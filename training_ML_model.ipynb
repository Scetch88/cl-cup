{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abaf0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e990b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/prp_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961089f",
   "metadata": {},
   "source": [
    "### Columns:\n",
    "\n",
    "* **text_id** - ID of initial text\n",
    "* **text** - initial raw text\n",
    "* **comment** - initial raw comment to text\n",
    "* **prp_text** - preprocessed cleaned text\n",
    "* **prp_com** - preprocessed cleaned comment\n",
    "* **score** - initial labels\n",
    "* **text_words_qty** - number of words in preprocessed text\n",
    "* **comment_words_qty** - number of words in preprocessed comment\n",
    "* **repeat_words** - number of repeated words in text and in comment\n",
    "* **repeat_rate_words** - ratio of repeated words to the number of words in comment\n",
    "* **link** - if there is a link in comment\n",
    "* **quoted** - if there is a quotaion in comment\n",
    "* **wr_sum** - sum of word weights in comment (weight are based on popularity)\n",
    "* **wr_len** - number of popular words in comment\n",
    "* **wr_rate** - ratio of *wr_sum* to *wr_len*\n",
    "* **wr_rate_tot** - ratio of *wr_sum* to *comment_words_qty*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d02c5",
   "metadata": {},
   "source": [
    "### Making labels for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643b0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lbl_best'] = np.where(df['score']==0, 1, 0) # mark as 1 only best comments\n",
    "df['lbl_worst'] = np.where(df['score']==4, 1, 0) # mark as 1 only worst comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad82030f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>comment</th>\n",
       "      <th>prp_text</th>\n",
       "      <th>prp_com</th>\n",
       "      <th>score</th>\n",
       "      <th>text_words_qty</th>\n",
       "      <th>comment_words_qty</th>\n",
       "      <th>repeat_words</th>\n",
       "      <th>repeat_rate_words</th>\n",
       "      <th>link</th>\n",
       "      <th>quoted</th>\n",
       "      <th>wr_sum</th>\n",
       "      <th>wr_len</th>\n",
       "      <th>wr_rate</th>\n",
       "      <th>wr_rate_tot</th>\n",
       "      <th>lbl_best</th>\n",
       "      <th>lbl_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0^0</td>\n",
       "      <td>- &amp;quot;0^0. Why? Because mathematicians said ...</td>\n",
       "      <td>0 0</td>\n",
       "      <td>quot 0 0 mathematician said really true quot d...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>292342</td>\n",
       "      <td>17</td>\n",
       "      <td>17196.587891</td>\n",
       "      <td>8352.628906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0^0</td>\n",
       "      <td>It&amp;#x27;s very important to note here that 0^0...</td>\n",
       "      <td>0 0</td>\n",
       "      <td>x27 important note 0 0 1 shorthand truth mathe...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005446</td>\n",
       "      <td>64</td>\n",
       "      <td>15710.093750</td>\n",
       "      <td>5778.425293</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0^0</td>\n",
       "      <td>A word from Knuth on the matter (warning: PDF)...</td>\n",
       "      <td>0 0</td>\n",
       "      <td>word knuth matter warning pdf http x2f x2f arx...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94678</td>\n",
       "      <td>7</td>\n",
       "      <td>13525.428711</td>\n",
       "      <td>4983.052734</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0^0</td>\n",
       "      <td>Students: Let&amp;#x27;s come up with some crazy p...</td>\n",
       "      <td>0 0</td>\n",
       "      <td>student let x27 come crazy proof based individ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270892</td>\n",
       "      <td>19</td>\n",
       "      <td>14257.473633</td>\n",
       "      <td>9674.713867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0^0</td>\n",
       "      <td>The real problem here is that x^y is a single ...</td>\n",
       "      <td>0 0</td>\n",
       "      <td>real problem x single shorthand refers fundame...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345465</td>\n",
       "      <td>27</td>\n",
       "      <td>12795.000000</td>\n",
       "      <td>4162.229004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The $0.001 DIY iPhone 4 Antenna Fix</td>\n",
       "      <td>Is this a joke that I'm not getting? Scotch ta...</td>\n",
       "      <td>0 001 diy iphone 4 antenna fix</td>\n",
       "      <td>joke getting scotch tape really problem real f...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247597</td>\n",
       "      <td>14</td>\n",
       "      <td>17685.500000</td>\n",
       "      <td>10765.086914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                 text  \\\n",
       "0        0                                  0^0   \n",
       "1        0                                  0^0   \n",
       "2        0                                  0^0   \n",
       "3        0                                  0^0   \n",
       "4        0                                  0^0   \n",
       "5        1  The $0.001 DIY iPhone 4 Antenna Fix   \n",
       "\n",
       "                                             comment  \\\n",
       "0  - &quot;0^0. Why? Because mathematicians said ...   \n",
       "1  It&#x27;s very important to note here that 0^0...   \n",
       "2  A word from Knuth on the matter (warning: PDF)...   \n",
       "3  Students: Let&#x27;s come up with some crazy p...   \n",
       "4  The real problem here is that x^y is a single ...   \n",
       "5  Is this a joke that I'm not getting? Scotch ta...   \n",
       "\n",
       "                         prp_text  \\\n",
       "0                             0 0   \n",
       "1                             0 0   \n",
       "2                             0 0   \n",
       "3                             0 0   \n",
       "4                             0 0   \n",
       "5  0 001 diy iphone 4 antenna fix   \n",
       "\n",
       "                                             prp_com  score  text_words_qty  \\\n",
       "0  quot 0 0 mathematician said really true quot d...      3               2   \n",
       "1  x27 important note 0 0 1 shorthand truth mathe...      0               2   \n",
       "2  word knuth matter warning pdf http x2f x2f arx...      4               2   \n",
       "3  student let x27 come crazy proof based individ...      1               2   \n",
       "4  real problem x single shorthand refers fundame...      2               2   \n",
       "5  joke getting scotch tape really problem real f...      0               7   \n",
       "\n",
       "   comment_words_qty  repeat_words  repeat_rate_words  link  quoted   wr_sum  \\\n",
       "0                 35             1           0.028571     0       1   292342   \n",
       "1                174             1           0.005747     0       1  1005446   \n",
       "2                 19             0           0.000000     1       0    94678   \n",
       "3                 28             0           0.000000     0       0   270892   \n",
       "4                 83             1           0.012048     0       0   345465   \n",
       "5                 23             1           0.043478     0       0   247597   \n",
       "\n",
       "   wr_len       wr_rate   wr_rate_tot  lbl_best  lbl_worst  \n",
       "0      17  17196.587891   8352.628906         0          0  \n",
       "1      64  15710.093750   5778.425293         1          0  \n",
       "2       7  13525.428711   4983.052734         0          1  \n",
       "3      19  14257.473633   9674.713867         0          0  \n",
       "4      27  12795.000000   4162.229004         0          0  \n",
       "5      14  17685.500000  10765.086914         1          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e008e",
   "metadata": {},
   "source": [
    "### Spliting the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02706ed3",
   "metadata": {},
   "source": [
    "To speed up training we will use 30% of dataset.  \n",
    "20% we will keep for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "777be6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of texts: 85987\n",
      "30% of dataset, text_index <= 25796\n",
      "20% for test, 25796 > text_index <= 42994\n"
     ]
    }
   ],
   "source": [
    "total_texts = df['text_id'].max() + 1\n",
    "print(f'Total number of texts: {total_texts}')\n",
    "print(f'30% of dataset, text_index <= {total_texts*0.3:.0f}')\n",
    "print(f'20% for test, {total_texts*0.3:.0f} > text_index <= {total_texts*0.5:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f51ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['text_id']<=25796]\n",
    "df_test = df[(df['text_id']>25796)&(df['text_id']<=42994)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0f1b9",
   "metadata": {},
   "source": [
    "### Choosing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c288beb",
   "metadata": {},
   "source": [
    "We will try 2 approaches to data that we have:\n",
    "1. **Feature based approach:**  \n",
    "  \n",
    "- We saw with EDA that best and worst comments may be separated by strong model, e.g. boosting.  \n",
    "- Lets use 2 models which will be trained for binary classification to identify best and worst comments based on set of features. \n",
    "- With *predict_proba* we will get sorted ranks of comments made by each model.  \n",
    "\n",
    "2. **Context based approach:**  \n",
    "  \n",
    "- Our first approach takes into account only technical parameters of texts and comments.    \n",
    "- To overview our data completely we should process texts and comments from contextual point of view.    \n",
    "- Lets use pretrained NLP models from BERT family to build contextual embeddings.  \n",
    "- After to save time we will train 2 SLP models (single layer perceptron) for binary classification to identify best and worst comments.\n",
    "  \n",
    "**Finally with 4 models we will get votes for the rank of comment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59193f3a",
   "metadata": {},
   "source": [
    "### Metric\n",
    "For measuaring the quality we will use NDCG metric.  \n",
    "We will compair NDCG of our approach with random metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d76ec",
   "metadata": {},
   "source": [
    "### 1. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be5cd8",
   "metadata": {},
   "source": [
    "a. Prediction of best comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26e2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['lbl_best']\n",
    "X = df_train[['text_id', \n",
    "              'text_words_qty', \n",
    "              'comment_words_qty', \n",
    "              'repeat_words', \n",
    "              'repeat_rate_words', \n",
    "              'link', 'quoted', \n",
    "              'wr_sum', \n",
    "              'wr_len', \n",
    "              'wr_rate', \n",
    "              'wr_rate_tot'\n",
    "             ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7195a7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6149203\ttest: 0.6146569\tbest: 0.6146569 (0)\ttotal: 171ms\tremaining: 51.2s\n",
      "50:\tlearn: 0.4551979\ttest: 0.4579585\tbest: 0.4579152 (41)\ttotal: 906ms\tremaining: 4.42s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4579152188\n",
      "bestIteration = 41\n",
      "\n",
      "Shrink model to first 42 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6147086\ttest: 0.6152830\tbest: 0.6152830 (0)\ttotal: 13.7ms\tremaining: 4.09s\n",
      "50:\tlearn: 0.4549483\ttest: 0.4599954\tbest: 0.4597638 (31)\ttotal: 755ms\tremaining: 3.69s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4597638211\n",
      "bestIteration = 31\n",
      "\n",
      "Shrink model to first 32 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6148458\ttest: 0.6149988\tbest: 0.6149988 (0)\ttotal: 35.9ms\tremaining: 10.7s\n",
      "50:\tlearn: 0.4552672\ttest: 0.4573549\tbest: 0.4572746 (44)\ttotal: 828ms\tremaining: 4.04s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4572314959\n",
      "bestIteration = 61\n",
      "\n",
      "Shrink model to first 62 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6148986\ttest: 0.6149621\tbest: 0.6149621 (0)\ttotal: 13.6ms\tremaining: 4.05s\n",
      "50:\tlearn: 0.4552900\ttest: 0.4577593\tbest: 0.4576773 (30)\ttotal: 736ms\tremaining: 3.59s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.457677296\n",
      "bestIteration = 30\n",
      "\n",
      "Shrink model to first 31 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6148297\ttest: 0.6149072\tbest: 0.6149072 (0)\ttotal: 12.6ms\tremaining: 3.76s\n",
      "50:\tlearn: 0.4550823\ttest: 0.4587506\tbest: 0.4585547 (36)\ttotal: 761ms\tremaining: 3.71s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4585546865\n",
      "bestIteration = 36\n",
      "\n",
      "Shrink model to first 37 iterations.\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=111)\n",
    "\n",
    "cats = ['link', 'quoted']\n",
    "\n",
    "ctbs = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    ctbs.append(CatBoostClassifier(iterations=300, verbose=50, early_stopping_rounds=20))\n",
    "    ctbs[i].fit(X.loc[train_index].drop(['text_id'], axis=1), y.loc[train_index], \n",
    "                eval_set=(X.loc[test_index].drop(['text_id'], axis=1), y.loc[test_index]),\n",
    "                cat_features=cats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42b45a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment_words_qty</td>\n",
       "      <td>48.544777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wr_sum</td>\n",
       "      <td>12.128198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wr_len</td>\n",
       "      <td>11.638581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wr_rate_tot</td>\n",
       "      <td>6.277957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>link</td>\n",
       "      <td>6.069504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>repeat_rate_words</td>\n",
       "      <td>3.925666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>repeat_words</td>\n",
       "      <td>3.904905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wr_rate</td>\n",
       "      <td>3.896895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text_words_qty</td>\n",
       "      <td>2.439242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quoted</td>\n",
       "      <td>1.174273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature Id  Importances\n",
       "0  comment_words_qty    48.544777\n",
       "1             wr_sum    12.128198\n",
       "2             wr_len    11.638581\n",
       "3        wr_rate_tot     6.277957\n",
       "4               link     6.069504\n",
       "5  repeat_rate_words     3.925666\n",
       "6       repeat_words     3.904905\n",
       "7            wr_rate     3.896895\n",
       "8     text_words_qty     2.439242\n",
       "9             quoted     1.174273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctbs[0].get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0b30b",
   "metadata": {},
   "source": [
    "b. Prediction of worst comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780f24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_w = df_train['lbl_worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4093412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6214494\ttest: 0.6221212\tbest: 0.6221212 (0)\ttotal: 17.1ms\tremaining: 5.11s\n",
      "50:\tlearn: 0.4710223\ttest: 0.4758597\tbest: 0.4757286 (33)\ttotal: 795ms\tremaining: 3.88s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4757286064\n",
      "bestIteration = 33\n",
      "\n",
      "Shrink model to first 34 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6207162\ttest: 0.6205951\tbest: 0.6205951 (0)\ttotal: 14.7ms\tremaining: 4.38s\n",
      "50:\tlearn: 0.4716765\ttest: 0.4738076\tbest: 0.4737475 (40)\ttotal: 815ms\tremaining: 3.98s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4737474859\n",
      "bestIteration = 40\n",
      "\n",
      "Shrink model to first 41 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6207212\ttest: 0.6205020\tbest: 0.6205020 (0)\ttotal: 13.7ms\tremaining: 4.09s\n",
      "50:\tlearn: 0.4715649\ttest: 0.4743990\tbest: 0.4741823 (31)\ttotal: 818ms\tremaining: 4s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4741822845\n",
      "bestIteration = 31\n",
      "\n",
      "Shrink model to first 32 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6216043\ttest: 0.6218219\tbest: 0.6218219 (0)\ttotal: 17.6ms\tremaining: 5.27s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4747901037\n",
      "bestIteration = 27\n",
      "\n",
      "Shrink model to first 28 iterations.\n",
      "Learning rate set to 0.168162\n",
      "0:\tlearn: 0.6218612\ttest: 0.6216827\tbest: 0.6216827 (0)\ttotal: 15.8ms\tremaining: 4.73s\n",
      "50:\tlearn: 0.4719269\ttest: 0.4730346\tbest: 0.4730080 (44)\ttotal: 827ms\tremaining: 4.04s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.473008004\n",
      "bestIteration = 44\n",
      "\n",
      "Shrink model to first 45 iterations.\n"
     ]
    }
   ],
   "source": [
    "ctbs_w = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y_w)):\n",
    "    ctbs_w.append(CatBoostClassifier(iterations=300, verbose=50, early_stopping_rounds=20))\n",
    "    ctbs_w[i].fit(X.loc[train_index].drop(['text_id'], axis=1), y_w.loc[train_index], \n",
    "                eval_set=(X.loc[test_index].drop(['text_id'], axis=1), y_w.loc[test_index]),\n",
    "                cat_features=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9179726b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment_words_qty</td>\n",
       "      <td>50.892024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wr_len</td>\n",
       "      <td>12.651188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wr_sum</td>\n",
       "      <td>9.999493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>link</td>\n",
       "      <td>6.607928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wr_rate_tot</td>\n",
       "      <td>4.705328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>repeat_words</td>\n",
       "      <td>3.711550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wr_rate</td>\n",
       "      <td>3.637839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>repeat_rate_words</td>\n",
       "      <td>3.408673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text_words_qty</td>\n",
       "      <td>2.682051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quoted</td>\n",
       "      <td>1.703927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature Id  Importances\n",
       "0  comment_words_qty    50.892024\n",
       "1             wr_len    12.651188\n",
       "2             wr_sum     9.999493\n",
       "3               link     6.607928\n",
       "4        wr_rate_tot     4.705328\n",
       "5       repeat_words     3.711550\n",
       "6            wr_rate     3.637839\n",
       "7  repeat_rate_words     3.408673\n",
       "8     text_words_qty     2.682051\n",
       "9             quoted     1.703927"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctbs_w[0].get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f793bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving lists of models\n",
    "\n",
    "with open('data/ML_model_best.pickle', 'wb') as pkl:\n",
    "    pickle.dump(ctbs, pkl)  \n",
    "\n",
    "with open('data/ML_model_worst.pickle', 'wb') as pkl:\n",
    "    pickle.dump(ctbs_w, pkl)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
